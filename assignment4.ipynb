{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57a3c62d",
   "metadata": {},
   "source": [
    "Face Recognition System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010b8743",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pickle\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"‚úÖ Libraries imported successfully!\")\n",
    "\n",
    "# Check camera availability\n",
    "try:\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    camera_available = cap.isOpened()\n",
    "    cap.release()\n",
    "    print(f\"üìπ Camera available: {camera_available}\")\n",
    "except:\n",
    "    camera_available = False\n",
    "    print(\"üìπ Camera not detected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9ac64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FaceRecognitionSystem:\n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize the Face Recognition System using OpenCV\"\"\"\n",
    "        # Initialize face detector\n",
    "        self.face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "        \n",
    "        # Initialize face recognizer\n",
    "        self.face_recognizer = cv2.face.LBPHFaceRecognizer_create()\n",
    "        \n",
    "        # Storage for face data\n",
    "        self.known_faces = []\n",
    "        self.known_names = []\n",
    "        self.known_labels = []\n",
    "        self.label_to_name = {}\n",
    "        self.name_to_label = {}\n",
    "        self.is_trained = False\n",
    "        self.next_label = 0\n",
    "        \n",
    "        print(\"üî• Face Recognition System initialized with OpenCV!\")\n",
    "    \n",
    "    def detect_faces(self, image):\n",
    "        \"\"\"Detect faces in an image using OpenCV\"\"\"\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        faces = self.face_cascade.detectMultiScale(gray, 1.1, 4, minSize=(30, 30))\n",
    "        return faces, gray\n",
    "    \n",
    "    def add_person(self, image_path_or_array, name):\n",
    "        \"\"\"Add a person to the recognition database\"\"\"\n",
    "        try:\n",
    "            # Handle both file path and numpy array\n",
    "            if isinstance(image_path_or_array, str):\n",
    "                image = cv2.imread(image_path_or_array)\n",
    "                if image is None:\n",
    "                    print(f\"‚ùå Could not load image: {image_path_or_array}\")\n",
    "                    return False\n",
    "            else:\n",
    "                image = image_path_or_array\n",
    "            \n",
    "            # Detect faces\n",
    "            faces, gray = self.detect_faces(image)\n",
    "            \n",
    "            if len(faces) > 0:\n",
    "                # Use the first face found\n",
    "                (x, y, w, h) = faces[0]\n",
    "                face_region = gray[y:y+h, x:x+w]\n",
    "                face_resized = cv2.resize(face_region, (100, 100))\n",
    "                \n",
    "                # Assign label to name\n",
    "                if name not in self.name_to_label:\n",
    "                    self.name_to_label[name] = self.next_label\n",
    "                    self.label_to_name[self.next_label] = name\n",
    "                    self.next_label += 1\n",
    "                \n",
    "                label = self.name_to_label[name]\n",
    "                \n",
    "                # Store face data\n",
    "                self.known_faces.append(face_resized)\n",
    "                self.known_labels.append(label)\n",
    "                self.known_names.append(name)\n",
    "                \n",
    "                print(f\"‚úÖ Added {name} to the database\")\n",
    "                return True\n",
    "            else:\n",
    "                print(f\"‚ùå No face found in image for {name}\")\n",
    "                return False\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error adding {name}: {str(e)}\")\n",
    "            return False\n",
    "    \n",
    "    def train_model(self):\n",
    "        \"\"\"Train the face recognition model\"\"\"\n",
    "        if len(self.known_faces) < 2:\n",
    "            print(\"‚ùå Need at least 2 face samples to train!\")\n",
    "            return False\n",
    "        \n",
    "        try:\n",
    "            # Train the LBPH recognizer\n",
    "            self.face_recognizer.train(self.known_faces, np.array(self.known_labels))\n",
    "            self.is_trained = True\n",
    "            print(\"‚úÖ Model trained successfully!\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Training failed: {str(e)}\")\n",
    "            return False\n",
    "    \n",
    "    def recognize_faces(self, image):\n",
    "        \"\"\"Recognize faces in an image\"\"\"\n",
    "        faces, gray = self.detect_faces(image)\n",
    "        face_names = []\n",
    "        \n",
    "        for (x, y, w, h) in faces:\n",
    "            face_region = gray[y:y+h, x:x+w]\n",
    "            face_resized = cv2.resize(face_region, (100, 100))\n",
    "            \n",
    "            if self.is_trained:\n",
    "                # Predict using trained model\n",
    "                label, confidence = self.face_recognizer.predict(face_resized)\n",
    "                \n",
    "                # Lower confidence means better match (opposite of face_recognition library)\n",
    "                if confidence < 100:  # Threshold for recognition\n",
    "                    name = self.label_to_name.get(label, \"Unknown\")\n",
    "                    confidence_score = max(0, (100 - confidence) / 100)  # Convert to 0-1 scale\n",
    "                else:\n",
    "                    name = \"Unknown\"\n",
    "                    confidence_score = 0\n",
    "            else:\n",
    "                name = \"Unknown\"\n",
    "                confidence_score = 0\n",
    "            \n",
    "            face_names.append((name, confidence_score))\n",
    "        \n",
    "        return faces, face_names\n",
    "    \n",
    "    def draw_results(self, image, face_locations, face_names):\n",
    "        \"\"\"Draw rectangles and names on the image\"\"\"\n",
    "        result_image = image.copy()\n",
    "        \n",
    "        for (x, y, w, h), (name, confidence) in zip(face_locations, face_names):\n",
    "            # Choose color based on recognition\n",
    "            color = (0, 255, 0) if name != \"Unknown\" else (0, 0, 255)\n",
    "            \n",
    "            # Draw rectangle around face\n",
    "            cv2.rectangle(result_image, (x, y), (x+w, y+h), color, 2)\n",
    "            \n",
    "            # Draw label\n",
    "            label = f\"{name} ({confidence:.2f})\" if name != \"Unknown\" else \"Unknown\"\n",
    "            cv2.rectangle(result_image, (x, y-35), (x+w, y), color, cv2.FILLED)\n",
    "            cv2.putText(result_image, label, (x + 6, y - 6), \n",
    "                       cv2.FONT_HERSHEY_DUPLEX, 0.6, (255, 255, 255), 1)\n",
    "        \n",
    "        return result_image\n",
    "    \n",
    "    def save_database(self, filename=\"face_database.pkl\"):\n",
    "        \"\"\"Save the face database\"\"\"\n",
    "        if not self.is_trained:\n",
    "            print(\"‚ùå No trained model to save!\")\n",
    "            return\n",
    "        \n",
    "        data = {\n",
    "            'known_faces': self.known_faces,\n",
    "            'known_labels': self.known_labels,\n",
    "            'known_names': self.known_names,\n",
    "            'label_to_name': self.label_to_name,\n",
    "            'name_to_label': self.name_to_label,\n",
    "            'next_label': self.next_label\n",
    "        }\n",
    "        \n",
    "        # Save the trained model\n",
    "        model_file = filename.replace('.pkl', '_model.yml')\n",
    "        self.face_recognizer.save(model_file)\n",
    "        \n",
    "        # Save other data\n",
    "        with open(filename, 'wb') as f:\n",
    "            pickle.dump(data, f)\n",
    "        print(f\"üíæ Database saved to {filename} and {model_file}\")\n",
    "    \n",
    "    def load_database(self, filename=\"face_database.pkl\"):\n",
    "        \"\"\"Load the face database\"\"\"\n",
    "        try:\n",
    "            # Load data\n",
    "            with open(filename, 'rb') as f:\n",
    "                data = pickle.load(f)\n",
    "            \n",
    "            self.known_faces = data['known_faces']\n",
    "            self.known_labels = data['known_labels']\n",
    "            self.known_names = data['known_names']\n",
    "            self.label_to_name = data['label_to_name']\n",
    "            self.name_to_label = data['name_to_label']\n",
    "            self.next_label = data['next_label']\n",
    "            \n",
    "            # Load trained model\n",
    "            model_file = filename.replace('.pkl', '_model.yml')\n",
    "            self.face_recognizer.read(model_file)\n",
    "            self.is_trained = True\n",
    "            \n",
    "            print(f\"üìÇ Database loaded from {filename}\")\n",
    "            print(f\"üë• Loaded {len(set(self.known_names))} people\")\n",
    "            return True\n",
    "        except FileNotFoundError:\n",
    "            print(f\"‚ùå Database file {filename} not found\")\n",
    "            return False\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error loading database: {str(e)}\")\n",
    "            return False\n",
    "\n",
    "# Initialize the system\n",
    "face_system = FaceRecognitionSystem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0811bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "\n",
    "def capture_person_photos(name, num_photos=5):\n",
    "    \"\"\"Capture photos from webcam for training\"\"\"\n",
    "    if not camera_available:\n",
    "        print(\"‚ùå Camera not available!\")\n",
    "        return []\n",
    "    \n",
    "    cap = cv2.VideoCapture(0)\n",
    "    photos = []\n",
    "    count = 0\n",
    "    \n",
    "    print(f\"üì∏ Capturing {num_photos} photos for {name}\")\n",
    "    print(\"üìã Instructions:\")\n",
    "    print(\"- Look at the camera\")\n",
    "    print(\"- Press SPACE to take a photo\")\n",
    "    print(\"- Press ESC to finish early\")\n",
    "    \n",
    "    while count < num_photos:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        # Flip frame for mirror effect\n",
    "        frame = cv2.flip(frame, 1)\n",
    "        \n",
    "        # Detect faces in current frame\n",
    "        faces, gray = face_system.detect_faces(frame)\n",
    "        \n",
    "        # Draw rectangles around detected faces\n",
    "        for (x, y, w, h) in faces:\n",
    "            cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "        \n",
    "        # Add instructions\n",
    "        cv2.putText(frame, f\"Capturing {name}: {count}/{num_photos}\", \n",
    "                   (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "        cv2.putText(frame, \"SPACE=Capture, ESC=Exit\", \n",
    "                   (10, 70), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "        \n",
    "        # Show face count\n",
    "        cv2.putText(frame, f\"Faces detected: {len(faces)}\", \n",
    "                   (10, 110), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)\n",
    "        \n",
    "        cv2.imshow('Capture Photos', frame)\n",
    "        \n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        if key == ord(' ') and len(faces) > 0:  # Space to capture\n",
    "            photos.append(frame.copy())\n",
    "            count += 1\n",
    "            print(f\"üì∑ Photo {count} captured!\")\n",
    "        elif key == 27:  # ESC to exit\n",
    "            break\n",
    "    \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    print(f\"‚úÖ Captured {len(photos)} photos for {name}\")\n",
    "    return photos\n",
    "\n",
    "def add_person_from_photos(name, photos):\n",
    "    \"\"\"Add a person using multiple photos\"\"\"\n",
    "    if not photos:\n",
    "        print(\"‚ùå No photos provided!\")\n",
    "        return False\n",
    "    \n",
    "    success_count = 0\n",
    "    for i, photo in enumerate(photos):\n",
    "        if face_system.add_person(photo, name):\n",
    "            success_count += 1\n",
    "        \n",
    "    if success_count > 0:\n",
    "        print(f\"‚úÖ Added {success_count}/{len(photos)} photos for {name}\")\n",
    "        # Train the model after adding new person\n",
    "        face_system.train_model()\n",
    "        return True\n",
    "    else:\n",
    "        print(f\"‚ùå Failed to add any photos for {name}\")\n",
    "        return False\n",
    "\n",
    "def live_recognition():\n",
    "    \"\"\"Start live face recognition\"\"\"\n",
    "    if not camera_available:\n",
    "        print(\"‚ùå Camera not available!\")\n",
    "        return\n",
    "    \n",
    "    if not face_system.is_trained:\n",
    "        print(\"‚ùå Model not trained! Add some people first and train the model.\")\n",
    "        return\n",
    "    \n",
    "    cap = cv2.VideoCapture(0)\n",
    "    print(\"üî¥ Live recognition started!\")\n",
    "    print(\"Press 'q' to quit, 's' to save frame\")\n",
    "    \n",
    "    frame_count = 0\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        # Flip frame for mirror effect\n",
    "        frame = cv2.flip(frame, 1)\n",
    "        \n",
    "        # Recognize faces\n",
    "        face_locations, face_names = face_system.recognize_faces(frame)\n",
    "        \n",
    "        # Draw results\n",
    "        result_frame = face_system.draw_results(frame, face_locations, face_names)\n",
    "        \n",
    "        # Add instructions\n",
    "        cv2.putText(result_frame, \"Press 'q' to quit, 's' to save\", \n",
    "                   (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "        cv2.putText(result_frame, f\"People in DB: {len(set(face_system.known_names))}\", \n",
    "                   (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 0), 2)\n",
    "        \n",
    "        cv2.imshow('Live Face Recognition', result_frame)\n",
    "        \n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        if key == ord('q'):\n",
    "            break\n",
    "        elif key == ord('s'):\n",
    "            filename = f\"recognition_frame_{frame_count}.jpg\"\n",
    "            cv2.imwrite(filename, result_frame)\n",
    "            print(f\"üíæ Frame saved as {filename}\")\n",
    "            frame_count += 1\n",
    "    \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    print(\"‚úÖ Live recognition stopped!\")\n",
    "\n",
    "def test_with_image(image_path):\n",
    "    \"\"\"Test recognition with an image file\"\"\"\n",
    "    try:\n",
    "        image = cv2.imread(image_path)\n",
    "        if image is None:\n",
    "            print(f\"‚ùå Could not load image: {image_path}\")\n",
    "            return\n",
    "        \n",
    "        print(f\"üß™ Testing recognition with {image_path}\")\n",
    "        \n",
    "        # Recognize faces\n",
    "        face_locations, face_names = face_system.recognize_faces(image)\n",
    "        \n",
    "        # Draw results\n",
    "        result_image = face_system.draw_results(image, face_locations, face_names)\n",
    "        \n",
    "        # Display results\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        \n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "        plt.title('Original Image')\n",
    "        plt.axis('off')\n",
    "        \n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.imshow(cv2.cvtColor(result_image, cv2.COLOR_BGR2RGB))\n",
    "        plt.title(f'Recognition Results ({len(face_locations)} faces)')\n",
    "        plt.axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Print results\n",
    "        for i, (name, confidence) in enumerate(face_names):\n",
    "            print(f\"Face {i+1}: {name} (Confidence: {confidence:.3f})\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error testing image: {str(e)}\")\n",
    "\n",
    "print(\"üõ†Ô∏è Helper functions ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0163208e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample data and test the system\n",
    "\n",
    "def create_sample_faces():\n",
    "    \"\"\"Create sample face images for testing\"\"\"\n",
    "    print(\"üé® Creating sample face data...\")\n",
    "    \n",
    "    # Create a simple face image for demonstration\n",
    "    def create_face_image(brightness=150, name=\"Person\"):\n",
    "        # Create a base image\n",
    "        img = np.full((300, 300, 3), brightness, dtype=np.uint8)\n",
    "        \n",
    "        # Add face-like features\n",
    "        center = (150, 150)\n",
    "        \n",
    "        # Face outline (oval)\n",
    "        cv2.ellipse(img, center, (80, 100), 0, 0, 360, (brightness-30, brightness-30, brightness-30), -1)\n",
    "        \n",
    "        # Eyes\n",
    "        cv2.circle(img, (125, 130), 12, (0, 0, 0), -1)  # Left eye\n",
    "        cv2.circle(img, (175, 130), 12, (0, 0, 0), -1)  # Right eye\n",
    "        \n",
    "        # Nose\n",
    "        cv2.circle(img, (150, 160), 8, (brightness-50, brightness-50, brightness-50), -1)\n",
    "        \n",
    "        # Mouth\n",
    "        cv2.ellipse(img, (150, 190), (25, 15), 0, 0, 180, (brightness-60, brightness-60, brightness-60), -1)\n",
    "        \n",
    "        return img\n",
    "    \n",
    "    # Create sample images\n",
    "    samples = {}\n",
    "    \n",
    "    # Alice - bright face\n",
    "    alice_img = create_face_image(180, \"Alice\")\n",
    "    samples[\"Alice\"] = alice_img\n",
    "    \n",
    "    # Bob - medium face  \n",
    "    bob_img = create_face_image(140, \"Bob\")\n",
    "    samples[\"Bob\"] = bob_img\n",
    "    \n",
    "    # Charlie - darker face\n",
    "    charlie_img = create_face_image(120, \"Charlie\")\n",
    "    samples[\"Charlie\"] = charlie_img\n",
    "    \n",
    "    return samples\n",
    "\n",
    "# Create and display sample data\n",
    "sample_faces = create_sample_faces()\n",
    "\n",
    "# Display the sample faces\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "fig.suptitle('Sample Face Data', fontsize=16)\n",
    "\n",
    "for i, (name, img) in enumerate(sample_faces.items()):\n",
    "    axes[i].imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    axes[i].set_title(f'{name}')\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Sample faces created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f19a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add sample people to the database and train\n",
    "\n",
    "print(\"üë• Adding people to the face recognition database...\")\n",
    "\n",
    "# Add each sample face to the system\n",
    "added_people = []\n",
    "for name, img in sample_faces.items():\n",
    "    success = face_system.add_person(img, name)\n",
    "    if success:\n",
    "        added_people.append(name)\n",
    "\n",
    "if added_people:\n",
    "    print(f\"‚úÖ Successfully added: {added_people}\")\n",
    "    \n",
    "    # Train the model with the added faces\n",
    "    print(\"üéØ Training the recognition model...\")\n",
    "    training_success = face_system.train_model()\n",
    "    \n",
    "    if training_success:\n",
    "        print(f\"‚úÖ Model trained successfully!\")\n",
    "        print(f\"üìä Database Status:\")\n",
    "        print(f\"People in database: {len(set(face_system.known_names))}\")\n",
    "        print(f\"Known people: {list(set(face_system.known_names))}\")\n",
    "        print(f\"Total face samples: {len(face_system.known_faces)}\")\n",
    "        \n",
    "        # Save the database\n",
    "        face_system.save_database(\"sample_face_database.pkl\")\n",
    "    else:\n",
    "        print(\"‚ùå Training failed!\")\n",
    "else:\n",
    "    print(\"‚ùå Failed to add any people to the database\")\n",
    "    print(\"The sample faces might not be detected by OpenCV's face detector\")\n",
    "    print(\"Try using real photos or webcam captures instead\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ac64f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the recognition system\n",
    "\n",
    "def create_test_image():\n",
    "    \"\"\"Create a test image with multiple faces\"\"\"\n",
    "    print(\"üß™ Creating test image with multiple people...\")\n",
    "    \n",
    "    # Create a larger test image\n",
    "    test_img = np.full((400, 600, 3), 200, dtype=np.uint8)\n",
    "    \n",
    "    # Add Alice's face (left side)\n",
    "    alice_face = sample_faces[\"Alice\"]\n",
    "    alice_resized = cv2.resize(alice_face, (150, 150))\n",
    "    test_img[50:200, 50:200] = alice_resized\n",
    "    \n",
    "    # Add Bob's face (right side) \n",
    "    bob_face = sample_faces[\"Bob\"]\n",
    "    bob_resized = cv2.resize(bob_face, (150, 150))\n",
    "    test_img[50:200, 400:550] = bob_resized\n",
    "    \n",
    "    # Add an unknown face (bottom center)\n",
    "    unknown_face = np.full((120, 120, 3), 160, dtype=np.uint8)\n",
    "    cv2.circle(unknown_face, (60, 60), 40, (100, 100, 100), -1)  # Different face\n",
    "    cv2.circle(unknown_face, (50, 50), 5, (255, 255, 255), -1)   # Eye\n",
    "    cv2.circle(unknown_face, (70, 50), 5, (255, 255, 255), -1)   # Eye\n",
    "    cv2.rectangle(unknown_face, (55, 70), (65, 80), (255, 255, 255), -1)  # Mouth\n",
    "    \n",
    "    test_img[250:370, 240:360] = unknown_face\n",
    "    \n",
    "    return test_img\n",
    "\n",
    "# Create and test the image\n",
    "test_image = create_test_image()\n",
    "\n",
    "print(\"üîç Running face recognition on test image...\")\n",
    "\n",
    "# Recognize faces in the test image\n",
    "face_locations, face_names = face_system.recognize_faces(test_image)\n",
    "\n",
    "# Draw results\n",
    "result_image = face_system.draw_results(test_image, face_locations, face_names)\n",
    "\n",
    "# Display results\n",
    "plt.figure(figsize=(15, 8))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(cv2.cvtColor(test_image, cv2.COLOR_BGR2RGB))\n",
    "plt.title('Test Image')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(cv2.cvtColor(result_image, cv2.COLOR_BGR2RGB))\n",
    "plt.title(f'Recognition Results ({len(face_locations)} faces detected)')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print detailed results\n",
    "print(f\"\\nüéØ Recognition Results:\")\n",
    "print(f\"Faces detected: {len(face_locations)}\")\n",
    "\n",
    "for i, (name, confidence) in enumerate(face_names):\n",
    "    status = \"‚úÖ Recognized\" if name != \"Unknown\" else \"‚ùì Unknown\"\n",
    "    print(f\"Face {i+1}: {name} (Confidence: {confidence:.3f}) {status}\")\n",
    "\n",
    "print(f\"\\nüìà System Performance:\")\n",
    "print(f\"Database size: {len(set(face_system.known_names)) if face_system.known_names else 0} people\")\n",
    "print(f\"Recognition accuracy: {len([n for n, c in face_names if n != 'Unknown'])}/{len(face_names)} faces recognized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0d3919",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usage Instructions and Live Demo\n",
    "\n",
    "print(\"üöÄ Face Recognition System Ready!\")\n",
    "print(\"\\nüìã Available Functions:\")\n",
    "print(\"1. capture_person_photos(name, num_photos) - Capture photos from webcam\")\n",
    "print(\"2. add_person_from_photos(name, photos) - Add person using multiple photos\")\n",
    "print(\"3. face_system.add_person(image, name) - Add person from single image\")\n",
    "print(\"4. live_recognition() - Start live camera recognition\")\n",
    "print(\"5. test_with_image(path) - Test with image file\")\n",
    "print(\"6. face_system.save_database(filename) - Save face database\")\n",
    "print(\"7. face_system.load_database(filename) - Load face database\")\n",
    "\n",
    "print(\"\\nüí° Quick Start Guide:\")\n",
    "print(\"For real people with camera:\")\n",
    "print(\"  photos = capture_person_photos('YourName', 5)\")\n",
    "print(\"  add_person_from_photos('YourName', photos)\")\n",
    "print(\"  live_recognition()\")\n",
    "\n",
    "print(\"\\nFor image files:\")\n",
    "print(\"  face_system.add_person('path/to/photo.jpg', 'PersonName')\")\n",
    "print(\"  face_system.train_model()  # Train after adding people\")\n",
    "print(\"  test_with_image('path/to/test.jpg')\")\n",
    "\n",
    "print(\"\\nExample workflow:\")\n",
    "print(\"  # Add multiple people\")\n",
    "print(\"  photos1 = capture_person_photos('Alice', 3)\")\n",
    "print(\"  add_person_from_photos('Alice', photos1)\")\n",
    "print(\"  photos2 = capture_person_photos('Bob', 3)\")\n",
    "print(\"  add_person_from_photos('Bob', photos2)\")\n",
    "print(\"  # Start recognition\")\n",
    "print(\"  live_recognition()\")\n",
    "\n",
    "print(f\"\\nüìä Current Status:\")\n",
    "print(f\"‚úÖ System initialized: True\")\n",
    "print(f\"üë• People in database: {len(set(face_system.known_names)) if face_system.known_names else 0}\")\n",
    "print(f\"üéØ Model trained: {face_system.is_trained}\")\n",
    "print(f\"üìπ Camera available: {camera_available}\")\n",
    "print(f\"üöÄ Ready for recognition: {face_system.is_trained}\")\n",
    "\n",
    "if camera_available and face_system.is_trained:\n",
    "    print(\"\\nüé¨ Uncomment below to start live recognition:\")\n",
    "    print(\"# live_recognition()\")\n",
    "elif camera_available:\n",
    "    print(\"\\nüì∏ Uncomment below to add yourself to the database:\")\n",
    "    print(\"# photos = capture_person_photos('YourName', 5)\")\n",
    "    print(\"# add_person_from_photos('YourName', photos)\")\n",
    "    print(\"# live_recognition()\")\n",
    "else:\n",
    "    print(\"\\nüìÅ For image files, use:\")\n",
    "    print(\"# face_system.add_person('path/to/your/photo.jpg', 'YourName')\")\n",
    "    print(\"# face_system.train_model()\")\n",
    "\n",
    "photos = capture_person_photos('YourName', 5)\n",
    "add_person_from_photos('YourName', photos) \n",
    "live_recognition()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
